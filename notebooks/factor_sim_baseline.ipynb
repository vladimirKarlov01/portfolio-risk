{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fdbc644a-e17f-4d0e-935e-8eb32b6a5dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import List, Union\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f38c5161-57c6-43d1-9498-c2593524b187",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = pd.read_csv('../data/all_data.csv').drop('Unnamed: 0', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2e052ca9-3994-4751-b687-99fbe1c0b307",
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.stattools import adfuller, acf, pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef60e655-ed98-4e1e-ac93-b44fa7c52b28",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "de07efac-07eb-4737-b639-f43b0474a666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_posterior_cov(\n",
    "    factor_list: list=['factor_1', 'factor_2'],\n",
    "    prior_cov: pd.DataFrame=pd.DataFrame(\n",
    "        {'factor_1': [1, 1.1], 'factor_2': [1.1, 2]},\n",
    "        index=['factor_1', 'factor_2']\n",
    "    ),\n",
    "    est_var=[1.1, 3],\n",
    "):\n",
    "    \"\"\"\n",
    "    склеиваем оценки дисперсий факторов и их ковариации\n",
    "    \"\"\"\n",
    "    assert list(prior_cov.columns)==list(prior_cov.index), 'unexpected corr matrix index'\n",
    "\n",
    "    LEN = len(factor_list)\n",
    "\n",
    "    # создаем матрицу и добавляем оценки дисперсий факторов \n",
    "    res_cov = np.zeros(shape=(LEN, LEN)) + np.diag(est_var)\n",
    "\n",
    "    # убираем лишнее и отсортировываем матрицу\n",
    "    prior_cov = prior_cov.loc[factor_list, factor_list].to_numpy()\n",
    "\n",
    "    # оставляем только ковариации\n",
    "    only_cov = prior_cov - np.diag(np.diagonal(prior_cov))\n",
    "\n",
    "    return res_cov + only_cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78e78923-8a54-4c31-bf07-13c8793052ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as sps\n",
    "\n",
    "def sample_multivariate_normal(\n",
    "    factor_list: list=['factor_1', 'factor_2'],\n",
    "    prior_cov: pd.DataFrame=pd.DataFrame(\n",
    "        {'factor_1': [1, 1.1], 'factor_2': [1.1, 2]},\n",
    "        index=['factor_1', 'factor_2']\n",
    "    ),\n",
    "    est_var=[1.1, 3],\n",
    "    est_mean: list=[10, 15],\n",
    "    size=100,\n",
    "    return_array=True,\n",
    "):\n",
    "    \"\"\"\n",
    "    В функцию подаем имена риск-факторов, средние и дисперсии в одном порядке!\n",
    "    \"\"\"\n",
    "    posterior_cov = calculate_posterior_cov(factor_list, prior_cov, est_var)\n",
    "    \n",
    "    sample = sps.multivariate_normal(\n",
    "        mean=est_mean,\n",
    "        cov=posterior_cov,\n",
    "    ).rvs(size=size)\n",
    "\n",
    "    return sample if return_array else pd.DataFrame(sample, factor_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "087c2ebc-4536-4c75-9f4c-5afa49b62170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def calculate_simulation_probability(\n",
    "    factor_list: list,\n",
    "    series_list: List[np.array],\n",
    "    prior_cov: pd.DataFrame,\n",
    "    est_var: List[np.array],\n",
    "    est_mean: List[np.array],\n",
    "    logging=False,\n",
    "    logreturn=True,\n",
    "):  \n",
    "    \"\"\"\n",
    "    Returns smth similar to Log Likelihood s. t. Multivariate distribution\n",
    "    using models individual forecasts and historical covariances\n",
    "    \"\"\"\n",
    "    \n",
    "    assert len(factor_list) == len(series_list), 'check number of factors'\n",
    "    assert len(set(len(array) for array in series_list)) == 1, 'check num of days in provided series'\n",
    "\n",
    "    prior_cov = prior_cov.loc[factor_list, factor_list]\n",
    "    \n",
    "    series_matrix = np.array(series_list).T\n",
    "    est_var_matrix = np.array(est_var).T\n",
    "    est_mean_matrix = np.array(est_mean).T\n",
    "\n",
    "    LENGTH = series_matrix.shape[0]\n",
    "    prob_list = [-1] * LENGTH\n",
    "    \n",
    "    for step in range(LENGTH):\n",
    "\n",
    "        posterior_cov = calculate_posterior_cov(\n",
    "            factor_list,\n",
    "            prior_cov,\n",
    "            est_var_matrix[step, :]\n",
    "        )\n",
    "\n",
    "        dist = sps.multivariate_normal(\n",
    "            mean=est_mean_matrix[step, :],\n",
    "            cov=posterior_cov\n",
    "        )\n",
    "\n",
    "        prob_list[step] = dist.pdf(series_matrix[step, :])\n",
    "\n",
    "    if logging:\n",
    "        print(prob_list)\n",
    "        \n",
    "    return np.sum(np.log(prob_list)) if logreturn else np.prod(prob_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "25a12b2d-b2e4-4828-82b3-8f7e5dcaada0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def find_last_acf_sign_lag(ts, drop_first = True):\n",
    "    acf, ci = sm.tsa.acf(ts, alpha=0.01)\n",
    "    first_zero, second_zero = 0, 0\n",
    "    for l in range(1, len(ci)):\n",
    "        if (0 >= ci[l][0] and 0 <= ci[l][1]):\n",
    "            if first_zero == 0:\n",
    "                first_zero = l - 1\n",
    "            else: \n",
    "                second_zero = l - 1\n",
    "                break\n",
    "    return first_zero\n",
    "    \n",
    "def find_last_pacf_sign_lag(ts, drop_first = True):\n",
    "    acf, ci = sm.tsa.pacf(ts, alpha=0.01)\n",
    "    first_zero, second_zero = 0, 0\n",
    "    for l in range(1, len(ci)):\n",
    "        if (0 >= ci[l][0] and 0 <= ci[l][1]):\n",
    "            if first_zero ==0:\n",
    "                first_zero = l - 1\n",
    "            else: \n",
    "                second_zero = l - 1\n",
    "                break\n",
    "    return first_zero   \n",
    "\n",
    "\n",
    "def fit_best_sarima_model(\n",
    "    series: pd.Series, \n",
    "    seasonal = 0,\n",
    "    ps = None,\n",
    "    d = None,\n",
    "    qs = None,\n",
    "    Ps = None,\n",
    "    D= None,\n",
    "    Qs = None,\n",
    "):\n",
    "    max_params = [\n",
    "        find_last_acf_sign_lag(series.diff().dropna()),\n",
    "        find_last_pacf_sign_lag(series.diff().dropna()), \n",
    "    1, 1]\n",
    "    \n",
    "    # print(max_params)\n",
    "    ps = range(0, max_params[0] + 1) if not ps else ps\n",
    "    d = [1] if not d else d\n",
    "    qs = range(0, max_params[1] + 1) if not qs else qs\n",
    "    Ps = range(0, max_params[2]) if not Ps else Ps\n",
    "    D = [1] if not D else D\n",
    "    Qs = range(0, max_params[3]) if not Qs else Qs\n",
    "    \n",
    "    grid = [ps, d, qs]\n",
    "\n",
    "    if seasonal:\n",
    "        grid += [Ps, D, Qs]\n",
    "    \n",
    "    parameters_list = list(product(*grid))\n",
    "    results = []\n",
    "    best_aic = float(\"inf\")\n",
    "    warnings.filterwarnings('ignore')\n",
    "\n",
    "    \n",
    "    for param in parameters_list:\n",
    "        #try except нужен, потому что на некоторых наборах параметров модель не обучается\n",
    "        order_list = (*param[:3],)\n",
    "        seasonal_list = (*param[3:7],) if seasonal else (0, 0, 0, 0)\n",
    "        \n",
    "        try:\n",
    "            model_sm = sm.tsa.SARIMAX(\n",
    "                series,\n",
    "                order=order_list, \n",
    "                seasonal_order=seasonal_list,\n",
    "            ).fit(disp=-1)\n",
    "            \n",
    "        #выводим параметры, на которых модель не обучается и переходим к следующему набору\n",
    "        except ValueError:\n",
    "            print('wrong parameters:', param)\n",
    "            continue\n",
    "        aic = model_sm.aic\n",
    "        \n",
    "        #сохраняем лучшую модель, aic, параметры\n",
    "        if aic < best_aic:\n",
    "            best_model = model_sm\n",
    "            best_aic = aic\n",
    "            best_param = param\n",
    "            \n",
    "        results.append([param, model_sm.aic])\n",
    "    \n",
    "    return best_model, best_param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "4859e61b-0a51-4eb4-89b8-f42faf79fbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (find_last_acf_sign_lag(train['aluminum'].diff().dropna()),\n",
    "# find_last_pacf_sign_lag(train['aluminum'].diff().dropna()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "70e86211-2024-46d1-99e3-c6df924ed48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_pacf(train['aluminum'].diff().dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "836cd0f4-81c1-42b7-a59c-4b70550b7b61",
   "metadata": {},
   "source": [
    "# Lets check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "5fce4d15-54c1-46ec-b4b2-a9a3038c08f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = all_data.set_index('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "fd5a8619-95c3-4c67-8017-619e9cae37d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = data[data.index < '2023-12-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "df192848-b1eb-4e6a-b999-12a4f03c364f",
   "metadata": {},
   "outputs": [],
   "source": [
    "factor_list = ['brent', 'eur_rub', 'aluminum']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "d407958d-c1b2-4f67-91a7-fede5780a86e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 3/3 [00:10<00:00,  3.60s/it]\n"
     ]
    }
   ],
   "source": [
    "model_dict = {}\n",
    "param_dict = {}\n",
    "\n",
    "for f in tqdm(factor_list):\n",
    "\n",
    "    model_dict[f], param_dict[f] = fit_best_sarima_model(train[f], ps=range(0, 6), qs=(0, 6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "8305185a-d422-4d18-a783-81e9bc9c703b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'brent': (2, 1, 0), 'eur_rub': (2, 1, 6), 'aluminum': (1, 1, 6)}"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0da304c8-d5a1-448d-a3d6-9b760235a974",
   "metadata": {},
   "source": [
    "# 1 step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "c9be6995-19ab-46aa-9b06-7c96e64c4af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_matrix = train[factor_list].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "fd97e2b4-010f-4a1d-98aa-b1b7d3c8cbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_step_means = []\n",
    "one_step_var = []\n",
    "\n",
    "for name in factor_list:\n",
    "\n",
    "    pred = model_dict[name].get_forecast(steps=1)\n",
    "\n",
    "    one_step_means.append(pred.predicted_mean.values[0])\n",
    "    one_step_var.append(pred.var_pred_mean.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "489ce103-2bba-480a-abc4-e6f5acc67bf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  80.68683012,   97.79079649, 2196.84175808])"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = sample_multivariate_normal(\n",
    "    factor_list=factor_list,\n",
    "    prior_cov=cov_matrix,\n",
    "    est_mean=one_step_means,\n",
    "    est_var=one_step_var,size=5000        \n",
    ")\n",
    "\n",
    "sample.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510d7838-e332-4614-be82-9201e0f90cd2",
   "metadata": {},
   "source": [
    "# N steps "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6685c9fb-720e-4843-b8b4-d4688f6eeb42",
   "metadata": {},
   "source": [
    "Можно конечно мб какую-то векторную авторегрессию сюда накрутить, но имхо оверкилл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "4694b03e-dff7-42cf-84f1-0088ecab9238",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEPS = 10\n",
    "\n",
    "means_series = []\n",
    "var_series = []\n",
    "\n",
    "for name in factor_list:\n",
    "\n",
    "    pred = model_dict[name].get_forecast(steps=STEPS)\n",
    "\n",
    "    means_series.append(pred.predicted_mean.values)\n",
    "    var_series.append(pred.var_pred_mean.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307199b0-5f67-4664-873c-5cd95fde526a",
   "metadata": {},
   "source": [
    "Потестим фукцию для \"вероятности\" траектории"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "3331a4a3-dd9b-4f09-bcbe-4e86702a0b74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# нужен численный индекс последней записи на трейне +1\n",
    "ANCHOR = train['brent'].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "28ccf5f3-164e-4d70-9a34-d807dbc7fbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "simulation_2 = []\n",
    "\n",
    "for name in factor_list:\n",
    "\n",
    "    simulation_2.append(\n",
    "        model_dict[name].simulate(nsimulations=STEPS,anchor=ANCHOR).values\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "c1f29b1e-5e1e-45f9-bac8-279ecb58a2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = calculate_simulation_probability(\n",
    "    factor_list,\n",
    "    simulation_1,\n",
    "    cov_matrix,\n",
    "    var_series,\n",
    "    means_series,\n",
    "    logging=False,\n",
    "    logreturn=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "7a6fa7fb-41ce-4b75-8be5-a98d43cb9cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulated_series_selection(\n",
    "    factor_list: list,\n",
    "    simulations: List[List[np.array]], # M iterations for N days for K factors\n",
    "    prior_cov: pd.DataFrame,\n",
    "    est_var: List[np.array],\n",
    "    est_mean: List[np.array],\n",
    "    threshold=None,\n",
    "    quantile=0.05,\n",
    "):\n",
    "    \n",
    "    NUM_SIM = len(simulations)\n",
    "    probs = [0] * NUM_SIM\n",
    "    \n",
    "    for sim in range(NUM_SIM):\n",
    "        \n",
    "        probs[sim] = calculate_simulation_probability(\n",
    "            factor_list,\n",
    "            simulations[sim],\n",
    "            prior_cov,\n",
    "            est_var,\n",
    "            est_mean,\n",
    "            logging=False,\n",
    "            logreturn=True\n",
    "        )\n",
    "\n",
    "    threshold = np.quantile(probs, quantile)\n",
    "    \n",
    "    for sim in range(NUM_SIM):\n",
    "        if probs[sim] >= threshold:\n",
    "            yield simulations[sim]\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "e0ce9223-f319-4937-a603-9d3faa077e12",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([81.73161585, 81.70051407, 80.28470491, 82.61922812, 83.80273262,\n",
       "        84.204375  , 85.63801739, 83.16580482, 85.02340704, 86.72693855]),\n",
       " array([100.52685996, 101.8409494 , 102.19929193, 101.35100257,\n",
       "         99.08673198,  99.13833293,  97.38063755,  95.5635618 ,\n",
       "         96.5623006 ,  98.89317195]),\n",
       " array([2168.98520265, 2161.99708466, 2156.79573212, 2239.41930567,\n",
       "        2176.13973835, 2149.47969647, 2132.97684705, 2207.33658065,\n",
       "        2199.90547324, 2140.07837643])]"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulated_series_selection(\n",
    "    factor_list,\n",
    "    [simulation_1, simulation_1, simulation_2],\n",
    "    cov_matrix,\n",
    "    var_series,\n",
    "    means_series,\n",
    ").__next__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "05e06904-3b6d-4dbc-a881-309cf980c2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_multivariate_normal()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "df2a0cab-3373-4da1-bc6f-990411f17ebb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data.set_index('date').cov()['aluminum']['brent']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
